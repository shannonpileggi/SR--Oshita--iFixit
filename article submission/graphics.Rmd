---
title: "Tables/Graphs for Article"
author: "Lisa Oshita"
date: "11/11/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
dir <- file.path(getwd(),"data")
out <- read.csv(file.path(dir, "answers_data.csv"))
list <- oshitar::variable_setup(out)
x <- list[[1]]
```

```{r}
model <- rms::cph(Surv(time_until_answer, answered) ~ new_category + new_user + 
                   contain_unanswered + contain_answered + title_questionmark + 
                   text_contain_punct + text_all_lower + update + prior_effort + weekday +
                   rcs(avg_tag_score, 5) + rcs(text_length, 4) + rcs(device_length, 5) + 
                   rcs(avg_tag_length, 4) + rcs(newline_ratio, 4), 
                   data = x, 
                   x = TRUE, y = TRUE, 
                   surv = TRUE)
```

### Distribution of answer times (Figure 1) 

```{r}
x$Answered <- NA
x$Answered[x$answered == 1] <- "Answered"
x$Answered[x$answered == 0] <- "Unanswered"

ggplot(x, aes(x = time_until_answer, fill = Answered)) +
  geom_histogram(bins = 15, alpha = 0.5, position = "identity") + 
  theme(axis.text = element_text(size = 13),
        axis.title = element_text(size = 15),
        plot.title = element_text(size = 17),
        legend.position = c(0.8, 0.8),
        legend.text = element_text(size = 13)) + 
  guides(fill = guide_legend(title = NULL)) + 
  scale_x_continuous("Time (hrs)") + 
  scale_y_continuous("Number of Questions") + 
  ggtitle("Distribution of Answer Times")
```


### KM Curve (Figure 2) 

```{r}
surv_object <- Surv(x$time_until_answer, x$answered, type = "right")
KM <- survfit(surv_object ~ 1, conf.type = "log-log")

# dashed line indicates the median survival time
ggsurvplot(KM, data = x, 
           risk.table = FALSE, 
           cumevents = FALSE, 
           conf.int = TRUE, conf.int.style = "step", 
           censor = FALSE,
           surv.median.line = "hv", 
           xlab = "Time (hours)", 
           xlim = c(0, 200), break.x.by = 20,
           ylim = c(0, 1), break.y.by = 0.1,
           surv.plot.height = 1, ggtheme = theme_bw(), 
           tables.height = 0.15, tables.theme = theme_cleantable(), fontsize = 2, na.rm = TRUE,
           title = "Kaplan-Meier Curve for all Questions",
           legend = "none")
```

### Table of percentiles (Table 1)

```{r}
q <- quantile(KM, c(0.25, 0.50, 0.55, 0.58, 0.60, 0.64)) # 64% is largest available survival probability
quantiles <- q$quantile
quantilesdf <- data.frame(Percent = names(quantiles), Time = round(quantiles, 2))
colnames(quantilesdf) <- c("Percent Answered", "Time (Hours)")
quantilesdf
```

### Univariate analysis results (Table 2) see univariate_analysis file

### Average CV metrics (Table 3 + 4) 
```{r}
# function for cross validation
crossval <- function(vars, train, test) {
  formula <- paste("Surv(time_until_answer, answered) ~ ", vars, sep = "")
  model <- rms::cph(as.formula(formula), data = train)
  
  train[["predictions"]] <- exp(predict(model, type = "lp"))
  metric <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = train)
  train_metrics <- data.frame(HR = exp(metric$coefficients), 
                              LR = round(metric$stats[3],2), 
                              pval = round(metric$stats[5],2),
                              R2 = round(metric$stats[8], 2),
                              AIC = stats::AIC(metric, k = 2),
                              Dxy = round(metric$stats[9],2), 
                              Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = train)$concordance)
  
  # predicting on test data
  test[["predictions"]] <- exp(predict(model, newdata = test, type = "lp"))
  
  # computing performance metrics 
  metric1 <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = test)
  test_metrics <- data.frame(HR = exp(metric1$coefficients), 
                             LR = round(metric1$stats[3],2), 
                             pval = round(metric1$stats[5],2), 
                             R2 = round(metric$stats[8], 2),
                             AIC = stats::AIC(metric1, k = 2),
                             Dxy = round(metric1$stats[9],2), 
                             Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = test)$concordance)
  
  # returns data frame with train/test metrics 
  statistics <- rbind(train_metrics, test_metrics)
  rownames(statistics) <- c("Training Data", "Test Data")
  return(statistics)
}

# function to average performance metrics, takes list of output from crossval
get_avgmetrics <- function(list) {
  avg <- rbind(train_avg = colMeans(purrr::map_df(1:length(list), ~rbind(list[[.]][1,]))), test_avg = colMeans(purrr::map_df(1:length(list), ~rbind(list[[.]][2,]))))
  return(avg)
}

trains <- list(train1, train2, train3, train4, train5)
trains <- purrr::map(trains, ~as.data.frame(.))
tests <- list(test1, test2, test3, test4, test5)
tests <- purrr::map(tests, ~as.data.frame(.))

# ------------------------------------------
# without splines
vars <- "new_category + new_user + contain_unanswered + contain_answered + title_questionmark + text_contain_punct + text_all_lower + update + prior_effort + weekday + avg_tag_score + text_length + device_length + avg_tag_length + newline_ratio"

cv_results <- purrr::map2(trains, tests, ~crossval(vars, .x, .y))
avg_results <- get_avgmetrics(cv_results)
avg_results

# ------------------------------------------
# with splines
vars1 <- "new_category + new_user + contain_unanswered + contain_answered + title_questionmark + text_contain_punct + text_all_lower + update + prior_effort + weekday + sqrt(avg_tag_score) + rcs(text_length, 4) + rcs(device_length, 5) + rcs(avg_tag_length, 4) + rcs(newline_ratio, 4)"

cv_results1 <- purrr::map2(trains, tests, ~crossval(vars1, .x, .y))
avg_results1 <- get_avgmetrics(cv_results1)
avg_results1
```


# residuals

```{r}
final <- rms::cph(Surv(time_until_answer, answered) ~ new_category + new_user + 
                  contain_unanswered + contain_answered + title_questionmark + 
                  text_contain_punct + text_all_lower + update + prior_effort + weekday + 
                  sqrt(avg_tag_score) + rcs(text_length, 4) + rcs(device_length, 5) + 
                  rcs(avg_tag_length, 4) + rcs(newline_ratio, 4), 
                  data = x, x = TRUE, 
                  y = TRUE, surv = TRUE)
final

x$mart <- residuals(final, type = "martingale")

ggplot(x, aes(x = avg_tag_score, y = mart)) + 
  geom_point() + 
  geom_smooth() + 
  ggtitle(paste("Martingale Residuals for average_tag_score")) + 
  scale_x_continuous("Average Tag Score (square root)") 

plotm <- function(var) {
  ggplot(x, aes(x = x[[var]], y = mart)) + 
    geom_point() + 
    geom_smooth() + 
    ggtitle(paste("Martingale Residuals for", var)) + 
    scale_x_continuous(var)
}
plotm("avg_tag_score")
plotm("text_length")
plotm("device_length")
plotm("avg_tag_length")
plotm("newline_ratio")


```

# final model on full data (table 5)

```{r}
# model statistics + parameters
# figure out how to get p-values 
parameterdf <- data.frame(variable = names(final$coefficients),
                          coefficients = round(unname(final$coefficients), 3))
parameterdf

modelstats <- data.frame(statistic = names(final$stats), 
                         value = round(unname(final$stats), 3))
modelstats

# ------------------------------------------
# cross-validation metrics 
x$predictions <- exp(predict(final, type = "lp"))

metric <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = x)
AIC(metric, k = 2) # 83125.55

final_metrics <- data.frame(HR = exp(metric$coefficients), 
                              LR = round(metric$stats[3],2), 
                              pval = round(metric$stats[5],2),
                              R2 = round(metric$stats[8], 2),
                              AIC = stats::AIC(metric, k = 2),
                              Dxy = round(metric$stats[9],2), 
                              Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = x)$concordance)
final_metrics 
```

