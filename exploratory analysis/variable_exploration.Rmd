---
title: "Exploring variables in the data"
output: 
  html_document: default
  pdf_document: default

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
dir <- file.path(getwd(),"data")
out <- read.csv(file.path(dir, "answers_data.csv"))

library(dplyr)
x <- out %>% 
  tbl_df() %>%
  filter(langid == "en")

x$time_until_answer <- (x$first_answer_date - x$post_date)/3600
empty <- which(is.na(x$time_until_answer))
for (i in empty) {
  x$time_until_answer[i] <- (x$download_date[i] - x$post_date[i])/3600
}

library(ggplot2)
library(survival)
library(epiR)
library(stringr)
library(rebus)
library(qdap)
library(tm)
```


```{r, functions, include = FALSE}
#function to plot KM_curves with ggplot (use when it's hard to read ggsurvplot output)
#takes survfit object, data set to work with, and optional x-axis limits as input, outputs ggplot KM curves
plot_surv <- function(survfit, data, xlim = NULL) {
  library(ggfortify)
  library(directlabels)
  
  df <- fortify(survfit, data = data)
  
  if (missing(xlim)) {
      
    if (!("strata" %in% names(df))) {
        ggplot(df, aes(x = time, y = surv)) + 
          geom_line() + 
          scale_y_continuous("Survival Probability") +
          scale_x_continuous("Time (hours)")
          ggtitle("Survival Curve")
        }
    if ("strata" %in% names(df)) {
      ggplot(df, aes(x = time, y = surv, color = strata)) + 
        geom_line() + 
        scale_y_continuous("Survival Probabilities") +
        scale_x_continuous("Time (hours)") + 
        ggtitle("Survival Curves") + 
        geom_dl(aes(label = strata), method = list(dl.trans(x = x + 0.2), "last.points", cex = 0.5))
    }
  } else {
      
      if (!("strata" %in% names(df))) {
        ggplot(df, aes(x = time, y = surv)) + 
          geom_line() + 
          scale_y_continuous("Survival Probability") +
          scale_x_continuous("Time (hours)", limits = xlim)
          ggtitle("Survival Curve")
      }

      if ("strata" %in% names(df)) {
        ggplot(df, aes(x = time, y = surv, color = strata)) + 
          geom_line() + 
          scale_y_continuous("Survival Probabilities") +
          scale_x_continuous("Time (hours)", limits = xlim) + 
          ggtitle("Survival Curves") + 
          geom_dl(aes(label = strata), method = list(dl.trans(x = x + 0.2), "last.points", cex = 0.5))
      }
  }
}

#function that prints out summary stats grouped by that variable 
sum_stats <- function(variable, data) {
  tbl <- x %>%
    group_by(data[[variable]]) %>%
    summarise(n = n(), median_time = median(time_until_answer), median_views = median(daily_views), prop_answered = sum(answered)/n) %>%
    arrange(median_time)
  names(tbl)[1] <- variable
  return(tbl)
}

#function to clean corpus (stopwrds is an optional argument)
clean_corpus <- function(corpus, stopwrds = NULL){
  if (is.null(stopwrds)) {
    corpus <- tm_map(corpus, stripWhitespace)
    corpus <- tm_map(corpus, content_transformer(tolower))
    corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "can", "will", "cant", "wont", "works", "get", "help", "need", "fix"))
    return(corpus)    
  } else {
    corpus <- tm_map(corpus, stripWhitespace)
    corpus <- tm_map(corpus, content_transformer(tolower))
    corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "can", "will", "cant", "wont", "works", "get", "help", "need", "fix", stopwrds))
    return(corpus)
  }
}

#function that takes in character vector and returns a data frame of words and frequencies sorted by most to least frequent, n and stopwrds are an optional arguments
freq_terms <- function(vec, n = NULL, stopwrds = NULL) {
  source <- VectorSource(vec)
  corpus <- VCorpus(source)
  
  if (is.null(stopwrds)) {
    cleaned_corpus <- clean_corpus(corpus) 
    dtm <- DocumentTermMatrix(cleaned_corpus, control = list(weighting = weightTfIdf))
    m <- as.matrix(dtm) 
    freq <- colSums(m)
    freq <- sort(freq, decreasing = TRUE)
    freq_df <- data.frame(word = names(freq), frequency = unname(freq))    
  } else {
    cleaned_corpus <- clean_corpus(corpus, stopwrds) 
    dtm <- DocumentTermMatrix(cleaned_corpus, control = list(weighting = weightTfIdf))
    m <- as.matrix(dtm) 
    freq <- colSums(m)
    freq <- sort(freq, decreasing = TRUE)
    freq_df <- data.frame(word = names(freq), frequency = unname(freq))
  }
  
  if (missing(n)) {
    return(freq_df)
  }
  else {
    return(freq_df[1:n,])
  }
}
```


### Category

##### summary stats grouped by category, arranged by median time

* NA's represent questions for devices that don't already exist on the website, treat as other?

```{r, echo = FALSE}
sum_stats("category", x)
```

##### log-rank test

```{r, echo = FALSE}
surv_object <- Surv(x$time_until_answer, x$answered, type = "right")

survdiff(surv_object~category, data = x)
KM_category <- survfit(surv_object~category, data = x)
plot_surv(KM_category, data = x)
```
##### zoomed in 
```{r, echo = FALSE}
plot_surv(KM_category, data = x, xlim = c(0,100))
```

### Subcategories

```{r, echo = FALSE}
x %>%
  group_by(subcategory) %>%
  summarise(n = n(), proportion = n/nrow(x), prop_ans = sum(answered)/n, median_time = median(time_until_answer)) %>%
  arrange(desc(n))
```

##### Is there a difference between iPhone and Android users? 

```{r, echo = FALSE}
x %>% 
  filter(subcategory == c("iPhone", "Android Phone")) %>%
  group_by(subcategory) %>%
  summarise(n = n(), median_time = median(time_until_answer), median_views = median(daily_views), prop_ans = sum(answered)/n)
```

##### textmining on iPhone and Android Phone text

##### Word cloud for most frequent terms among questions about iPhones

```{r, echo = FALSE}
android_data <- x %>%
  filter(subcategory == "Android Phone")
android_terms <- freq_terms(android_data$text, stopwrds = c("android", "phone"))

iphone_data <- x %>%
  filter(subcategory == "iPhone")
iphone_terms <- freq_terms(iphone_data$text, stopwrds = c("iphone", "phone"))


library(wordcloud)
library(RColorBrewer)

wordcloud(iphone_terms$word, iphone_terms$frequency, scale = c(3, 0.1), max.words = 100, colors = c("grey80", "darkgoldenrod1", "tomato"))
```

##### Word cloud for most frequent terms among questions involving Android Phones

```{r, echo = FALSE}
wordcloud(android_terms$word, android_terms$frequency, scale = c(3, 0.1), max.words = 100, colors = c("grey80", "darkgoldenrod1", "tomato"))
```


### Whether or not the question was categorized correctly

```{r, echo = FALSE}
prop_incorrect <- sum(is.na(x$category))/nrow(x)
```

* `r round(prop_incorrect*100, 2)`% of questions were categorized incorrectly

##### log-rank test

```{r, echo = FALSE}
x$categorized <- 0
x$categorized[!is.na(x$category)] <- 1

survdiff(surv_object~categorized, data = x)
KM_correct <- survfit(surv_object ~ as.factor(categorized), data = x)
plot_surv(KM_correct, data = x, xlim = c(0,100))
```


### Title Length

##### distribution of title lengths

```{r, title length, echo = FALSE}
x$title_length <- str_length(x$title)

ggplot(x, aes(x = title_length)) + 
  geom_histogram() + 
  scale_x_continuous("Length of Question Title", breaks = seq(0,100,10)) + 
  ggtitle("Distribution of Title Lengths")
```

* **min title length:** `r min(x$title_length)` characters
* **max title length:** `r max(x$title_length)` characters
* **mean title length:** `r round(mean(x$title_length),2)`
* **median:** `r median(x$title_length)`

##### average title length grouped by answered/unanswered questions

```{r, echo = FALSE}
x %>%
  group_by(as.factor(answered)) %>%
  summarise(avg_length = mean(title_length), n = n())

f <- x %>%
  filter(is.na(category))
```

##### average title length and median time grouped by category 

```{r, echo = FALSE}
x %>%
  group_by(category) %>%
  summarise(n = n(), avg_length = mean(title_length), median_time = median(time_until_answer)) %>%
  arrange(desc(avg_length))
```

### Text Length

```{r, echo = FALSE}
x$text_length <- str_length(x$text)

ggplot(x, aes(x = text_length)) + 
  geom_histogram() + 
  scale_x_continuous("Length of Text") + 
  ggtitle("Distribution of Text Lengths")
```

* **min text length:** `r min(x$text_length)` characters
* **max text length:** `r max(x$text_length)` characters
* **mean text length:** `r round(mean(x$text_length),2)` characters
* **median:** `r median(x$text_length)` characters

##### average/median text length and median time grouped by answered/unanswered questions

* may be evidence that questions with longer text length tend to get answered

```{r, echo = FALSE}
x %>%
  group_by(as.factor(answered)) %>%
  summarise(median_length = median(text_length), n = n())
```

##### determining which categories have the longest text lengths

```{r, echo = FALSE}
x %>%
  group_by(category) %>%
  summarise(median_length = median(text_length), n = n(), median_time = median(time_until_answer)) %>%
  arrange(desc(median_length))
```

### Device name length

```{r, device length, echo = FALSE}
x$device_length <- str_length(x$device)

ggplot(x, aes(x = device_length)) + 
  geom_histogram() + 
  scale_x_continuous("Length of Device Name") + 
  ggtitle("Distribution of Device Name Lengths")
```

* **min length:** `r min(x$device_length)` characters
* **max length:** `r max(x$device_length)` characters
* **mean length:** `r round(mean(x$device_length),2)` characters
* **median length:** `r median(x$device_length)` characters

##### average and median device length grouped by answered/unanswered questions

```{r, echo = FALSE}
x %>%
  group_by(as.factor(answered)) %>%
  summarise(avg_length = mean(device_length), n = n())
```

##### which categories have the longest device name lengths

```{r, echo = FALSE}
x %>%
  group_by(category) %>%
  summarise(avg_length = mean(device_length), n = n(), median_time = median(time_until_answer)) %>%
  arrange(median_time)
```


### n_tags

* n_tags included in questions: `r unique(x$n_tags)`
```{r, echo = FALSE}
prop_notags <- sum(x$n_tags == 0)/nrow(x)
```
* `r round(prop_notags*100,2)`% of questions don't have any tags

##### proportion table for n_tags

```{r, echo = FALSE}
round(prop.table(table(x$n_tags)), 3)
```

##### median time and proportion of questions answered grouped by n_tags

* questions with more tags tend to have faster answer times and are more likely to get answers

```{r, echo = FALSE}
sum_stats("n_tags", x)
```

##### log-rank test

```{r, echo = FALSE}
survdiff(surv_object ~ as.factor(n_tags), data = x)
KM_tags <- survfit(surv_object~as.factor(n_tags), data = x)
plot_surv(KM_tags, data = x)
```


### n_images

```{r, echo = FALSE}
prop_hasimage <- sum(x$n_images != 0)/nrow(x)
```

* `r round(prop_hasimage * 100, 2)`% of questions contain at least one image

##### frequency table for n_images

```{r, echo = FALSE}
table(x$n_images)
```

##### median time and proportion answered grouped by whether or not question contains an image

* questions that include at least one image tend to have faster answer times

```{r, echo = FALSE}
x$pic_included <- 0
x$pic_included[x$n_images != 0] <- 1

sum_stats("pic_included", x)
```

##### log-rank test 

```{r, echo = FALSE}
survdiff(surv_object ~ as.factor(pic_included), data = x)
KM_pic <- survfit(surv_object~as.factor(pic_included), data = x)
plot_surv(KM_pic, data = x)
plot_surv(KM_pic, data = x, xlim = c(0,250))
```


### new_user

```{r, echo = FALSE}
prop_new <- sum(x$new_user)/nrow(x)
```

* `r round(prop_new * 100, 2)`% of users asking a question were new

##### median time and proportion answered grouped by whether or not new user

```{r, echo = FALSE}
sum_stats("new_user", x)
```

##### More summary statistics grouped by new_user

```{r, echo = FALSE}
x %>%
  group_by(new_user) %>%
  summarise(n = n(), include_tag = sum(n_tags != 0)/n, include_pic = sum(n_images != 0)/n, mean_title = mean(title_length), mean_text = mean(text_length), mean_device = mean(device_length))
```

##### wordclouds for new users

* to see if there's a difference in the topics of the questions that new/continuing users ask 

```{r, echo = FALSE}
new <- x %>%
  filter(new_user == 1)

new_freq <- freq_terms1(new$text)
wordcloud(new_freq$word, new_freq$frequency, scale = c(3, 0.1), max.words = 100, colors = c("grey80", "darkgoldenrod1", "tomato"))
```

##### wordclouds for continuing users 

```{r, echo = FALSE}
continuing <- x %>%
  filter(new_user == 0)
cont_freq <- freq_terms1(continuing$text)
wordcloud(cont_freq$word, cont_freq$frequency, scale = c(3, 0.1), max.words = 100, colors = c("grey80", "darkgoldenrod1", "tomato"))
```


##### log-rank test

```{r, echo = FALSE}
survdiff(surv_object ~ as.factor(new_user), data = x)
KM_new <- survfit(surv_object~as.factor(new_user), data = x)
plot_surv(KM_new, data = x)
```

### daily_views

* **max average daily views for a question:** `r max(x$daily_views)`
* **min average daily views for a question:** `r min(x$daily_views)`
* **mean:** `r round(mean(x$daily_views), 2)`
* **median:** `r round(median(x$daily_views), 2)`


### Looking at when the question was posted

* unix time stamp: seconds since Jan 01 1970. (UTC)

```{r, echo = FALSE}
x$post_datetime <- as.POSIXct(x$post_date,origin="1970-01-01")
x$post_d <- format(x$post_datetime, "%m/%d/%y")
x$post_time <- format(x$post_datetime, " %H:%M:%S")
x$post_weekday <- factor(weekdays(x$post_datetime), levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
x$post_hour <- as.numeric(format(x$post_datetime,"%H"))

x$post_ampm <- "Night"
x$post_ampm[x$post_hour >= 5 & x$post_hour < 12] <- "Morning"
x$post_ampm[x$post_hour >= 12 & x$post_hour < 17] <- "Afternoon" #noon - 5pm 
x$postampm[x$post_hour >= 17 & x$post_hour < 20] <- "Evening" #5pm - 8pm 

posn_d <- position_dodge(width = 0.2)
ggplot(x, aes(x = post_weekday, fill = as.factor(answered))) + 
  geom_bar(position = posn_d, alpha = 0.6) + 
  scale_y_continuous("Number of Questions") +
  ggtitle("Distribution of questions posted over a week")

ggplot(x, aes(x = post_hour)) + 
  geom_bar() + 
  scale_y_continuous("Number of Questions") + 
  ggtitle("Distribution of all questions posted over a day") + 
  scale_x_continuous("Hour of the Day", breaks = seq(0, 23, by = 1))

ggplot(x, aes(x = post_hour, fill = as.factor(answered))) + 
  geom_bar(position = posn_d, alpha = 0.6) + 
  scale_y_continuous("Number of Questions") + 
  ggtitle("Distribution of questions posted over a day, grouped by answered/unanswered") +
  scale_x_continuous("Hour of the Day", breaks = seq(0, 23, by = 1))
```

##### Median time grouped by day of the week

```{r, echo = FALSE}
sum_stats("post_weekday", x)
```

##### Median time/avg views/prop answered grouped by hour

```{r, echo = FALSE}
sum_stats("post_hour", x)
```

##### log-rank test + survival curves for weekday 

```{r, echo = FALSE}
survdiff(surv_object ~ post_weekday, data = x)
KM_weekday <- survfit(surv_object ~ post_weekday, data = x)
plot_surv(KM_weekday, data = x)
```

##### log-rank test and survival curves for hour of the day

```{r, echo = FALSE}
survdiff(surv_object ~ as.factor(post_hour), data = x)
KM_hour <- survfit(surv_object ~ as.factor(post_hour), data = x)
plot_surv(KM_hour, data = x)
```


##### log-rank test and survival curves for ampm

```{r, echo = FALSE}
survdiff(surv_object ~ post_ampm, data = x)
KM_ampm <- survfit(surv_object ~ post_ampm, data = x)
plot_surv(KM_ampm, data = x)
```

### Looking at when answers are posted 

```{r, echo = FALSE}
x$ans_datetime <- as.POSIXct(x$first_answer_date, origin="1970-01-01")
x$ans_d <- format(x$ans_datetime, "%m/%d/%y")
x$ans_time <- format(x$ans_datetime, " %H:%M:%S")
x$ans_weekday <- factor(weekdays(x$ans_datetime), levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
x$ans_hour <- as.numeric(format(x$ans_datetime,"%H"))

ggplot(subset(x, !is.na(ans_weekday)), aes(x = ans_weekday)) + 
  geom_bar() + 
  ggtitle("Distribution of answers posted over a week")

library(gridExtra)

plot1 <- ggplot(x, aes(x = post_hour)) + 
  geom_bar() + 
  ggtitle("Distribution of questions posted over a day") +
  scale_x_continuous("Hour of the Day", breaks = seq(0, 23, by = 1))

plot2 <- ggplot(subset(x, !is.na(ans_weekday)), aes(x = ans_hour)) + 
  geom_bar() + 
  ggtitle("Distribution of answers posted over a day") + 
  scale_x_continuous("Hour of the Day", breaks = seq(0, 23, by = 1))

grid.arrange(plot1, plot2, nrow=2, ncol=1)
```


