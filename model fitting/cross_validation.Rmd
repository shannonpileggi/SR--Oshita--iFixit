---
title: "Predictive modeling with cross validation"
author: "Lisa Oshita"
date: "8/10/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE}
x <- oshitar::setup()
library(survival)
library(stringr)
library(rebus)
library(dplyr)
library(stats)
library(ggplot2)
```

### Creating cross-validation plan with k = 5

```{r, echo = FALSE}
set.seed(444)
splitPlan <- vtreat::kWayCrossValidation(nrow(x), 5, NULL, NULL)
str(splitPlan)
```

### Building the model on one of the training data sets

##### Fitting model with all significant variables (univariate analysis p-value < 0.01), select variables using stepwise functions 

```{r}
first <- coxph(Surv(time_until_answer, answered) ~ category + as.factor(new_user) + contain_unanswered + title_questionmark + text_length + text_contain_punct + as.factor(num_freq_tags) + as.factor(n_tags) + contain_answered + newline_ratio + text_all_lower + update + greeting + capital_text + prior_effort + gratitude + ampm + n_images + weekday + device_length + title_beginwh, data = train1)
AIC(first, k = 2) #65294.56

# backwards step-wise selection with selectCox function
# converting to factors since function doesn't work with as.factor
train1$new_user <- as.factor(train1$new_user)
train1$num_freq_tags <- as.factor(train1$num_freq_tags)
train1$n_tags <- as.factor(train1$n_tags)

model1 <- pec::selectCox(Surv(time_until_answer, answered) ~ category + new_user + contain_unanswered + title_questionmark + text_length + text_contain_punct + num_freq_tags + n_tags + contain_answered + newline_ratio + text_all_lower + update + greeting + capital_text + prior_effort + gratitude + ampm + n_images + weekday + device_length + title_beginwh, data = train1, rule = "aic")
# results
results1 <- coxph(Surv(time_until_answer, answered) ~ category + new_user + contain_unanswered + title_questionmark + contain_answered + text_all_lower + update + ampm + device_length, data = train1)
AIC(results1, k = 2) #65285.49
summary(results1)

# backward/forward step-wise selection with stepAIC function from MASS package
model2 <- MASS::stepAIC(first, direction = "both", k = 2)
# results
results2 <- coxph(Surv(time_until_answer, answered) ~ category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh, data = train1)
AIC(results2, k = 2) # 65277.47
s <- summary(results2)
nrow(s$coefficients)

```

### Adding interaction terms 

```{r}
# working with model from backward/forward stepwise selection

# adding interaction terms
# adding title_questionmark*title_beginwh
model2.o <- coxph(Surv(time_until_answer, answered) ~ category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh, data = train1)
AIC(model2.o, k = 2) # 65274.49
oshitar::compare_nested(model2.o, results2)

# adding new_user*update
model2.o1 <- coxph(Surv(time_until_answer, answered) ~ category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + new_user*update, data = train1)
AIC(model2.o1, k = 2) # 65272.55
oshitar::compare_nested(model2.o1, results2)

# adding new_user*ampm 
model2.o2 <- coxph(Surv(time_until_answer, answered) ~ category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + new_user*ampm, data = train1)
AIC(model2.o2, k = 2) # 65271.84
oshitar::compare_nested(model2.o2, results2)

# all signficant interaction terms 
model_i <- coxph(Surv(time_until_answer, answered) ~ category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh + new_user*update + new_user*ampm, data = train1)
AIC(model_i, k = 2) # 65263.35
```

##### recoding category variable

* group all apple products together (use str_detect to search for Apple, ipad, ipod)
* recode left over Phones to Android/Other Phone
* group household + appliance as "Home"
* group car and truck + vehicle as "Vehicle"
* set a rule: any category with less than 50 questions gets grouped with "Other"

```{r}
# pie chart of product categories
ggplot(train1, aes(x = factor(1), fill = category)) + geom_bar(width = 1) + 
  coord_polar(theta = "y")

train1 %>%
  filter(new_category == "Electronics") %>%
  group_by(subcategory) %>%
  summarise(median = median(time_until_answer), n = n(), prop_a = sum(answered)/n) %>%
  arrange(median)

train1 %>%
  group_by(new_category) %>%
  summarise(median = median(time_until_answer), n = n(), prop_a = sum(answered)/n) %>%
  arrange(median)

#===================================================
# recoding category variable
train1$new_category <- as.character(train1$category)

# grouping apple products together
apple_terms <- c("apple", "ipod", "ipad")
train1$apple <- str_detect(str_to_lower(train1$device), pattern = START %R% or1(apple_terms) %R% SPC)
train1$new_category[train1$apple == TRUE | train1$subcategory == "iPhone" | train1$category == "Mac"] <- "Apple Product"

# renaming left over phones 
train1$new_category[train1$new_category == "Phone"] <- "Android/Other Phone"
# merge household and appliance into "Home"
train1$new_category[train1$new_category == "Appliance" | train1$new_category == "Household"] <- "Home"
# merging Car and Truck with Vehicle 
train1$new_category[train1$new_category == "Car and Truck" | train1$new_category == "Vehicle"] <- "Vehicle"

# if there are less than 100 questions in a category, group them with other
counts <- train1 %>%
  group_by(new_category) %>%
  summarise(n = n())
for (i in which(counts$n <= 100)) {
  train1$new_category[train1$new_category == counts$new_category[i]] <- "Other"
}
table(train1$new_category)
#===================================================

model_new <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh, data = train1)
AIC(model_new, k = 2) #64999.87

#new_cateogry*new_user
#new_cateogry*
model_new1 <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + new_category*new_user, data = train1)
AIC(model_new1, k = 2) # 64994.49
oshitar::compare_nested(model_new1, model_new)

# model with ALL interactions
# model with new_category
model_full <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh + new_user*update + new_user*ampm + new_category*new_user, data = train1)
AIC(model_full, k = 2) # 64978.87
summary(model_full)
```

### residuals, PH assumption

* Martingale residuals
    + plot for each continuous predictor 
    + assess adequacy of functional form of predictors, or suggest a potential form 
* Deviance residuals
    + check for outliers identify questions poorly predicted by the model 
    + one plot, examine questions with |residuals| > 2.5
* Schoenfeld residuals
    + one plot for each predictor 
    + if loess curve is flat, proportional hazard assumption is not violated, doesn't depend on time. Distinct pattern indicates violation of this assumption
    + **from the plots:** new_user, title_questionmark, num_freq_tags (1), ampm (Morning, Night), weekday (Thursday, Saturday), new_user*AMPM (morning, night) may violate PH assumption 
* Score residuals
    + check for influential observations. ID quesitons who's predictor values highly effect parameter estimates
    + plot for each predictor 
* **figure out how to identify certain points on ggplots**
* statified on new_category, AIC dropped drastically. But this means that I can't compare the different groups in new_category 
```{r}
#=============================================
#martingale residuals
train1$mart <- residuals(model_full, type = "martingale")

ggplot(train1, aes(x = device_length, y = mart)) + 
  geom_point() + 
  geom_smooth() + 
  ggtitle(paste("Martingale Residuals for device_length")) + 
  scale_x_continuous("Device_length")

#=============================================
#deviance residuals 
train1$deviance <- residuals(model_full, type = "deviance")
ggplot(train1, aes(x = 1:nrow(train1), y = deviance)) + 
  geom_point() + 
  scale_x_continuous("Question index") + 
  scale_y_continuous(breaks = seq(-4, 4, by = 0.5))
# quite a few questions have a deviance residual of larger than 2.5 

#=============================================
#schoenfeld residuals
schoen <- as.data.frame(residuals(model_full, type = "schoenfeld"))
# complete event times sorted from shortest to longest
schoen$comp_times <- sort(train1[train1$answered != 0,]$time_until_answer)

plot_schoen <- function(var) {
  ggplot(schoen, aes(x = comp_times, y = schoen[[var]])) + 
    geom_point() + 
    geom_smooth() + 
    ggtitle(paste("Schoenfeld Residuals for", var)) + 
    scale_y_continuous("Residuals")
}
names <- names(schoen)[-ncol(schoen)]
purrr::map(names, plot_schoen)

#=============================================
# score residuals
score <- as.data.frame(residuals(model_full, type = "score"))
# function to plot score residuals
plot_score <- function(column) {
  ggplot(score, aes(x = 1:nrow(score), y = score[[column]])) + 
    geom_point() + 
    geom_smooth() + 
    ggtitle(paste("Score residuals for", column)) + 
    scale_y_continuous("Score Residuals") + 
    scale_x_continuous("Question index")
}
columns <- names(score)
purrr::map(columns, plot_score)

#=============================================
# formal test of PH assumption
ph_test <- data.frame(predictors = rownames(cox.zph(model_full)$table), cox.zph(model_full)$table) 
rownames(ph_test) = NULL
ph_test <- ph_test %>%
  arrange(p)

# stratifying on new_category
strat_model <- coxph(Surv(time_until_answer, answered) ~ strata(new_category) + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh + new_user*update + new_user*ampm, data = train1)
AIC(strat_model, k = 2) # 49766.8
summary(strat_model)

# stratifying on new_user
strat_model1 <- coxph(Surv(time_until_answer, answered) ~ new_category + strata(new_user) + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh, data = train1)
AIC(strat_model1, k = 2) # 60543.75
summary(strat_model1)

# final model: stratified on new_category
final <- strat_model
```


### Predicting on the test data

##### variable set up in test data 

* categorical variables must be the same across data sets, but I want the categorical variable to change with each data set, any way to do this? 

```{r}
test1 <- x[splitPlan[[1]]$app, ]

#setting up variables in test1
#=============================================
test1$category <- as.character(test1$category)
test1$category[is.na(test1$category)] <- "Other"
#new_category
test1$new_category <- test1$category
apple_terms <- c("apple", "ipod", "ipad")
test1$apple <- str_detect(str_to_lower(test1$device), pattern = START %R% or1(apple_terms) %R% SPC)
test1$new_category[test1$apple == TRUE | test1$subcategory == "iPhone" | test1$category == "Mac"] <- "Apple Product"
test1$new_category[test1$new_category == "Phone"] <- "Android/Other Phone"
test1$new_category[test1$new_category == "Appliance" | test1$new_category == "Household"] <- "Home"
test1$new_category[test1$new_category == "Car and Truck" | test1$new_category == "Vehicle"] <- "Vehicle"
test1$new_category[test1$new_category == "Computer Hardware" | test1$new_category == "Media Player" | test1$new_category == "Apparel"] <- "Other"
# counts <- test1 %>%
#   group_by(new_category) %>%
#   summarise(n = n(), prop = n/nrow(test1))
# for (i in which(counts$prop <= 0.01)) {
#   test1$new_category[test1$new_category == counts$new_category[i]] <- "Other"
# }
#=============================================
#weekday
test1$datetime <- as.POSIXct(test1$post_date,origin="1970-01-01")
test1$weekday <- factor(weekdays(test1$datetime), levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
#=============================================
#ampm
test1$hour <- as.numeric(format(test1$datetime,"%H"))
test1$ampm <- "Night"
test1$ampm[test1$hour >= 5 & test1$hour < 12] <- "Morning"
test1$ampm[test1$hour >= 12 & test1$hour < 17] <- "Afternoon" #noon - 5pm
test1$ampm[test1$hour >= 17 & test1$hour < 20] <- "Evening" #5pm - 8pm
#=============================================
# text length
test1$text_length <- str_length(test1$text)
#=============================================
# device name length
test1$device_length <- str_length(test1$device)
#=============================================
# if the title ends with a question mark
library(rebus)
test1$title_questionmark <- str_detect(test1$title, pattern = QUESTION %R% END)
#=============================================
# if title begins with "wh"
test1$title_beginwh <- str_detect(str_to_lower(test1$title), pattern = "^wh")
#=============================================
test1$capital_text <- str_detect(as.character(test1$text), pattern = "^[[:upper:]]")
#=============================================
test1$update <- str_detect(test1$text, pattern = "===")
#=============================================
test1$newline_ratio <- str_count(test1$text, pattern = "\n")/str_length(test1$text)
#=============================================
# frequent tags
split_tags <- str_split(test1$tags, ", ", simplify = TRUE)
tag_vector <- as.vector(split_tags)
tag_vector <- tag_vector[which(tag_vector != "")]
unique_tags <- unique(tag_vector)

tag_freq <- data.frame(tag = unique_tags, percent = purrr::map_dbl(unique_tags, ~mean(rowSums(split_tags == .) > 0)))
tag_freq <- tag_freq %>%
              arrange(desc(percent))

#creating average frequency score variable
test1$tag1 <- split_tags[,1]
test1$tag2 <- split_tags[,2]
test1$tag3 <- split_tags[,3]
test1$tag4 <- split_tags[,4]

assign_score <- function(data, variable) {
  score <- rep(0, nrow(data))
  notempty <- which(data[[variable]] != "")
  for (i in notempty) {
    score[i] <- tag_freq$percent[which(tag_freq$tag == data[[variable]][i])]
  }
  return(score)
}
test1$score1 <- assign_score(test1, "tag1")
test1$score2 <- assign_score(test1, "tag2")
test1$score3 <- assign_score(test1, "tag3")
test1$score4 <- assign_score(test1, "tag4")
test1$avg_tag_score <- (test1$score1 + test1$score2 + test1$score3 + test1$score4)/as.numeric(test1$n_tags)
test1$avg_tag_score[is.nan(test1$avg_tag_score)] <- 0
#=============================================
# if question contains "frequent" tag
percentile80 <- quantile(test1$avg_tag_score, probs = 0.80)

test1$frequent_tag <- FALSE
test1$frequent_tag[test1$avg_tag_score >= percentile80] <- TRUE
#=============================================
#frequent terms in unanswered/answered questions
answered <- test1 %>%
  tbl_df() %>% 
  filter(answered == 1)
unanswered <- test1 %>%
  tbl_df() %>% 
  filter(answered == 0)

library(qdap)
library(tm)
terms_a <- oshitar::get_freq_terms(answered$title, stopwords = c("can", "will", "cant", "wont", "works", "get", "help", "need", "fix"))
terms_a$prop_in_answered <- terms_a$frequency/nrow(terms_a)
colnames(terms_a)[2] <- "frequency_a"

terms_u <- oshitar::get_freq_terms(unanswered$title, stopwords = c("can", "will", "cant", "wont", "works", "get", "help", "need", "fix"))
terms_u$prop_in_unanswered <- terms_u$frequency/nrow(terms_u)
colnames(terms_u)[2] <- "frequency_u"

combined <- dplyr::full_join(terms_a, terms_u, by = "word")
combined$ratio <- combined$prop_in_answered / combined$prop_in_unanswered

p_threshold <- 0.01
ratio_threshold <- 1

freq_terms_u <- combined %>%
                  filter(prop_in_unanswered > p_threshold) %>%
                  filter(ratio < ratio_threshold)
freq_terms_a <- combined %>%
                  filter(prop_in_answered > p_threshold) %>%
                  filter(ratio > ratio_threshold)

test1$contain_unanswered <- str_detect(as.character(test1$title), pattern = or1(freq_terms_u$word))
test1$contain_answered <- str_detect(as.character(test1$title), pattern = or1(freq_terms_a$word))

test1$new_user <- as.factor(test1$new_user)

#=============================================
# predicting on the test data 

#356 NAs in the predictions
test_predict <- predict(model_full, newdata = test1, type = "risk", se.fit = TRUE)
test1$predictions <- test_predict[[1]]

metric <- coxph(Surv(time_until_answer, answered) ~ predictions, data = test1)
summary(metric)
AIC(metric, k = 2)
```

```{r}
# function to set up variables for test data 
variable_setup <- function(data) {
  data$category <- as.character(data$category)
  data$category[is.na(data$category)] <- "Other"

  data$new_category <- data$category
  apple_terms <- c("apple", "ipod", "ipad")
  data$apple <- str_detect(str_to_lower(data$device), pattern = START %R% or1(apple_terms) %R% SPC)
  data$new_category[data$apple == TRUE | data$subcategory == "iPhone" | data$category == "Mac"] <- "Apple Product"
  data$new_category[data$new_category == "Phone"] <- "Android/Other Phone"
  data$new_category[data$new_category == "Appliance" | data$new_category == "Household"] <- "Home"
  data$new_category[data$new_category == "Car and Truck" | data$new_category == "Vehicle"] <- "Vehicle"
  data$new_category[data$new_category == "Computer Hardware" | data$new_category == "Media Player" |
                     data$new_category == "Apparel"] <- "Other"
  #=============================================
  #weekday
  data$datetime <- as.POSIXct(data$post_date,origin="1970-01-01")
  data$weekday <- factor(weekdays(data$datetime), levels = c("Monday", "Tuesday", "Wednesday", 
                                                             "Thursday", "Friday", "Saturday", "Sunday"))
  #=============================================
  #ampm
  data$hour <- as.numeric(format(data$datetime,"%H"))
  data$ampm <- "Night"
  data$ampm[data$hour >= 5 & data$hour < 12] <- "Morning"
  data$ampm[data$hour >= 12 & data$hour < 17] <- "Afternoon" #noon - 5pm
  data$ampm[data$hour >= 17 & data$hour < 20] <- "Evening" #5pm - 8pm
  #=============================================
  # text length
  data$text_length <- str_length(data$text)
  #=============================================
  # device name length
  data$device_length <- str_length(data$device)
  #=============================================
  # if the title ends with a question mark
  library(rebus)
  data$title_questionmark <- str_detect(data$title, pattern = QUESTION %R% END)
  #=============================================
  # if title begins with "wh"
  data$title_beginwh <- str_detect(str_to_lower(data$title), pattern = "^wh")
  #=============================================
  data$capital_text <- str_detect(as.character(data$text), pattern = "^[[:upper:]]")
  #=============================================
  data$update <- str_detect(data$text, pattern = "===")
  #=============================================
  data$newline_ratio <- str_count(data$text, pattern = "\n")/str_length(data$text)
  #=============================================
  # frequent tags
  split_tags <- str_split(data$tags, ", ", simplify = TRUE)
  tag_vector <- as.vector(split_tags)
  tag_vector <- tag_vector[which(tag_vector != "")]
  unique_tags <- unique(tag_vector)

  tag_freq <- data.frame(tag = unique_tags, percent = purrr::map_dbl(unique_tags, ~mean(rowSums(split_tags == .) > 0)))
  tag_freq <- tag_freq %>%
              arrange(desc(percent))

  #creating average frequency score variable
  data$tag1 <- split_tags[,1]
  data$tag2 <- split_tags[,2]
  data$tag3 <- split_tags[,3]
  data$tag4 <- split_tags[,4]

  assign_score <- function(data, variable) {
    score <- rep(0, nrow(data))
    notempty <- which(data[[variable]] != "")
    for (i in notempty) {
      score[i] <- tag_freq$percent[which(tag_freq$tag == data[[variable]][i])]
    }
    return(score)
  }
  data$score1 <- assign_score(data, "tag1")
  data$score2 <- assign_score(data, "tag2")
  data$score3 <- assign_score(data, "tag3")
  data$score4 <- assign_score(data, "tag4")
  data$avg_tag_score <- (data$score1 + data$score2 + data$score3 + 
                            data$score4)/as.numeric(data$n_tags)
  data$avg_tag_score[is.nan(data$avg_tag_score)] <- 0
  #=============================================
  # if question contains "frequent" tag
  percentile80 <- quantile(data$avg_tag_score, probs = 0.80)

  data$frequent_tag <- FALSE
  data$frequent_tag[data$avg_tag_score >= percentile80] <- TRUE
  #=============================================
  #frequent terms in unanswered/answered questions
  answered <- data %>%
      tbl_df() %>% 
      filter(answered == 1)
  unanswered <- data %>%
    tbl_df() %>% 
    filter(answered == 0)

  library(qdap)
  library(tm)
  terms_a <- oshitar::get_freq_terms(answered$title, stopwords = c("can", "will", "cant", "wont", "works", "get", "help", "need", "fix"))
  terms_a$prop_in_answered <- terms_a$frequency/nrow(terms_a)
  colnames(terms_a)[2] <- "frequency_a"

  terms_u <- oshitar::get_freq_terms(unanswered$title, stopwords = c("can", "will", "cant", "wont", "works", "get", "help", "need", "fix"))
  terms_u$prop_in_unanswered <- terms_u$frequency/nrow(terms_u)
  colnames(terms_u)[2] <- "frequency_u"

  combined <- dplyr::full_join(terms_a, terms_u, by = "word")
  combined$ratio <- combined$prop_in_answered / combined$prop_in_unanswered

  p_threshold <- 0.01
  ratio_threshold <- 1

  freq_terms_u <- combined %>%
                    filter(prop_in_unanswered > p_threshold) %>%
                    filter(ratio < ratio_threshold)
  freq_terms_a <- combined %>%
                    filter(prop_in_answered > p_threshold) %>%
                    filter(ratio > ratio_threshold)

  data$contain_unanswered <- str_detect(as.character(data$title), pattern = or1(freq_terms_u$word))
  data$contain_answered <- str_detect(as.character(data$title), pattern = or1(freq_terms_a$word))

  data$new_user <- as.factor(data$new_user)
  
  return(data)
}


```



