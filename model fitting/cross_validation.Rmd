---
title: "Predictive modeling with cross validation"
author: "Lisa Oshita"
date: "8/10/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, data setup, echo = FALSE}
x <- oshitar::setup()
library(survival)
library(stringr)
library(rebus)
library(dplyr)
library(stats)
library(ggplot2)
```

### Creating cross-validation plan with k = 5

```{r, echo = FALSE}
set.seed(444)
splitPlan <- vtreat::kWayCrossValidation(nrow(x), 5, NULL, NULL)
str(splitPlan)

train1 <- x[splitPlan[[1]]$train, ]
```

### Building the model on one of the training data sets

##### Fitting model with all significant variables (univariate analysis p-value < 0.01)

```{r, echo = FALSE}
fit <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + log10(text_length) + title_questionmark + title_beginwh + sqrt(newline_ratio) + sqrt(avg_tag_score) + text_contain_punct + text_all_lower + update + greeting + as.factor(n_tags) + gratitude + prior_effort + ampm + n_images + weekday, data = train1)

model <- MASS::stepAIC(fit, direction = "both", k = 2)
#results of stepAIC (but keeping contain_answered)
results <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday, data = train1)
summary(results)
AIC(results, k = 2) # 64965.89

# adding in spline on device_length
model_spline <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC"), data = train1)
AIC(model_spline, k = 2) # 64907.21

# adding in spline on text_length
model_spline1 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC") + pspline(text_length, df = 0, method = "AIC"), data = train1)
AIC(model_spline1, k = 2) # 64894.01

# adding in spline on avg_tag_length
model_spline2 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC") + pspline(text_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC"), data = train1)
summary(model_spline2)
AIC(model_spline2, k = 2) # 64848.5

anova(model_spline2)

#=====================================================
# adding interaction between title_questionmark + title_beginwh (probably leave out)
# probably leave interactions out, don't do much for the model 

resultse <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + title_questionmark + title_beginwh + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC") + pspline(text_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC") + title_questionmark*title_beginwh, data = train1)
summary(resultse)
AIC(resultse, k = 2) # 64843
```

# using rcs (restricted cubic spline) in rms package 
* fit knots at quantiles of the predictor 
* recommended in Regression Modeling Strategies to have 5 knots for large data sets 
```{r}
unname(quantile(train1$device_length, c(0.05, 0.275, 0.5, 0.725, 0.95)))

library(rms)
model <- cph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + rcs(device_length, unname(quantile(train1$device_length, c(0.05, 0.275, 0.5, 0.65, 0.95)))), data = train1)
AIC(model_spline, k = 2) # 64907.21
model
```



### residuals, PH assumption

* Martingale residuals
    + plot for each continuous predictor 
    + assess adequacy of functional form of predictors, or suggest a potential form 
* Deviance residuals
    + check for outliers identify questions poorly predicted by the model 
    + one plot, examine questions with |residuals| > 2.5
* Schoenfeld residuals
    + one plot for each predictor 
    + if loess curve is flat, proportional hazard assumption is not violated, doesn't depend on time. Distinct pattern indicates violation of this assumption
    + **from the plots:** new_user, title_questionmark, num_freq_tags (1), ampm (Morning, Night), weekday (Thursday, Saturday), new_user*AMPM (morning, night) may violate PH assumption 
* Score residuals
    + check for influential observations. ID quesitons who's predictor values highly effect parameter estimates
    + plot for each predictor 
* **figure out how to identify certain points on ggplots**

```{r, residuals, echo = FALSE}
#=============================================
#martingale residuals
train1$mart <- residuals(model_full, type = "martingale")

ggplot(train1, aes(x = device_length, y = mart)) + 
  geom_point() + 
  geom_smooth() + 
  ggtitle(paste("Martingale Residuals for device_length")) + 
  scale_x_continuous("Device_length")

#=============================================
#deviance residuals 
train1$deviance <- residuals(model_full, type = "deviance")
ggplot(train1, aes(x = 1:nrow(train1), y = deviance)) + 
  geom_point() + 
  scale_x_continuous("Question index") + 
  scale_y_continuous(breaks = seq(-4, 4, by = 0.5)) + 
  ggtitle("Deviance Residuals")
# quite a few questions have a deviance residual of larger than 2.5 

#=============================================
#schoenfeld residuals
schoen <- as.data.frame(residuals(model_full, type = "schoenfeld"))
# complete event times sorted from shortest to longest
schoen$comp_times <- sort(train1[train1$answered != 0,]$time_until_answer)

plot_schoen <- function(var) {
  ggplot(schoen, aes(x = comp_times, y = schoen[[var]])) + 
    geom_point() + 
    geom_smooth() + 
    ggtitle(paste("Schoenfeld Residuals for", var)) + 
    scale_y_continuous("Residuals")
}
names <- names(schoen)[-ncol(schoen)]
purrr::map(names, plot_schoen)

#=============================================
# score residuals
score <- as.data.frame(residuals(model_full, type = "score"))
# function to plot score residuals
plot_score <- function(column) {
  ggplot(score, aes(x = 1:nrow(score), y = score[[column]])) + 
    geom_point() + 
    geom_smooth() + 
    ggtitle(paste("Score residuals for", column)) + 
    scale_y_continuous("Score Residuals") + 
    scale_x_continuous("Question index")
}
columns <- names(score)
purrr::map(columns, plot_score)

#=============================================
# working with rms::which.influence to id influential points
c <- rms::cph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh + new_user*update + new_user*ampm + new_category*new_user, x = TRUE, y = TRUE, data = train1)
influence <- rms::which.influence(c)
rms::show.influence(influence, train1)

#=============================================
# formal test of PH assumption
options(scipen=999)
ph_test <- data.frame(predictors = rownames(cox.zph(model_full)$table), cox.zph(model_full)$table) 
rownames(ph_test) = NULL
ph_test <- ph_test %>%
  arrange(p)

#=============================================
# addression PH assumption violations

# stratifying on new_category
strat_model <- coxph(Surv(time_until_answer, answered) ~ strata(new_category) + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh + new_user*update + new_user*ampm, data = train1)
AIC(strat_model, k = 2) # 49766.8
summary(strat_model)

# stratifying on new_user
strat_model1 <- coxph(Surv(time_until_answer, answered) ~ new_category + strata(new_user) + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh, data = train1)
AIC(strat_model1, k = 2) # 60543.75
summary(strat_model1)

# stratifying on ampm 
strat_model2 <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + strata(ampm) + weekday + device_length + title_beginwh + title_questionmark*title_beginwh, data = train1)
AIC(strat_model2, k = 2) # 54447.8
summary(strat_model2)

# stratifying on ampm, new_user, new_category
strat_model3 <- coxph(Surv(time_until_answer, answered) ~ strata(new_category) + strata(new_user) + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + strata(ampm) + weekday + device_length + title_beginwh + title_questionmark*title_beginwh, data = train1)
AIC(strat_model3, k = 2) # 35370.81
summary(strat_model3)
```


### Performance metric on training data set

* survConcordance: 
    + Concordance is defined as Pr(agreement) for any two randomly chosen observations, where in this case agreement means that the observation with the shorter survival time of the two also has the larger risk score. The predictor (or risk score) will often be the result of a Cox model or other regression
    + some of the pairs are incomparable. For instance a pair of times (5+, 8), the first being a censored value. We do not know whether the first survival time is greater than or less than the second
    + observations that are comparable, pairs may also be tied on survival time (but only if both are uncensored) or on the predictor. The final concondance is (agree + tied/2)/(agree + disagree + tied)
    

```{r}
# working with model_spline2 (model with all splines)
train1$predictions <- predict(object = model_spline2, type = "risk") # should I predict "lp" instead of "risk"
(performance <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = train1, x = TRUE, y = TRUE, se.fit = TRUE, residuals = TRUE))

survConcordance(Surv(time_until_answer, answered) ~ predictions, data = train1) # Concordance = 0.6382697
Hmisc::rcorrcens(Surv(time_until_answer, answered) ~ predictions, data = train1)

```


### Predicting on the test data

* categorical variables must be the same across data sets, but I want the categorical variable to change with each data set, any way to do this? 

```{r, echo = FALSE}
# function to perform cross validation + compute performance metrics
crossvalidate <- function(train, test) {
 
  # building model on training data set
  model <- survival::coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC") + pspline(text_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC"), data = train)
  
  # performance metrics for training data 
  train[["predictions"]] <- predict(model, type = "risk")
  metric <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = train)
  train_metrics <- data.frame(HR = exp(metric$coefficients), 
                              LR = round(metric$stats[3],2), 
                              pval = round(metric$stats[5],2), 
                              Dxy = round(metric$stats[9],2), 
                              AIC = stats::AIC(metric, k = 2), 
                              Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = train)$concordance)

  # predicting on test data
  test[["predictions"]] <- predict(model, newdata = test, type = "risk")
  
  # computing performance metrics 
  metric1 <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = test)
  test_metrics <- data.frame(HR = exp(metric1$coefficients), 
                             LR = round(metric1$stats[3],2), 
                             pval = round(metric1$stats[5],2), 
                             Dxy = round(metric1$stats[9],2), 
                             AIC = stats::AIC(metric1, k = 2), 
                             Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = test)$concordance)
  
  # returns data frame with train/test metrics 
  statistics <- rbind(train_metrics, test_metrics)
  rownames(statistics) <- c("Training Data", "Test Data")
  return(statistics) 
}

#=============================================
test1 <- x[splitPlan[[1]]$app, ]
iteration1 <- crossvalidate(train1, test1)

#=============================================
train2 <- x[splitPlan[[2]]$train, ]
test2 <- x[splitPlan[[2]]$app, ]
iteration2 <- crossvalidate(train2, test2)

#=============================================
train3 <- x[splitPlan[[3]]$train, ]
test3 <- x[splitPlan[[3]]$app, ]
iteration3 <- crossvalidate(train3, test3)

#=============================================
train4 <- x[splitPlan[[4]]$train, ]
test4 <- x[splitPlan[[4]]$app, ]
iteration4 <- crossvalidate(train4, test4)

#=============================================
train5 <- x[splitPlan[[5]]$train, ]
test5 <- x[splitPlan[[5]]$app, ]
iteration5 <- crossvalidate(train5, test5)

iteration1
iteration2
iteration3
iteration4
iteration5
```


```{r}
# without pspline on text_length (if take out pspline on text_length, pvalue for fifth iteration goes back down to 0 (from 0.53))
crossvalidate1 <- function(train, test) {
 
  # building model on training data set
  model <- survival::coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC"), data = train)
  
  # performance metrics for training data 
  train[["predictions"]] <- predict(model, type = "risk")
  metric <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = train)
  train_metrics <- data.frame(HR = exp(metric$coefficients), 
                              LR = round(metric$stats[3],2), 
                              pval = round(metric$stats[5],2), 
                              Dxy = round(metric$stats[9],2), 
                              AIC = stats::AIC(metric, k = 2), 
                              Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = train)$concordance)

  # predicting on test data
  test[["predictions"]] <- predict(model, newdata = test, type = "risk")
  
  # computing performance metrics 
  metric1 <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = test)
  test_metrics <- data.frame(HR = exp(metric1$coefficients), 
                             LR = round(metric1$stats[3],2), 
                             pval = round(metric1$stats[5],2), 
                             Dxy = round(metric1$stats[9],2), 
                             AIC = stats::AIC(metric1, k = 2), 
                             Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = test)$concordance)
  
  # returns data frame with train/test metrics 
  statistics <- rbind(train_metrics, test_metrics)
  rownames(statistics) <- c("Training Data", "Test Data")
  return(statistics) 
}

i1 <- crossvalidate1(train1, test1)
i2 <- crossvalidate1(train2, test2)
i3 <- crossvalidate1(train3, test3)
i4 <- crossvalidate1(train4, test4)
i5 <- crossvalidate1(train5, test5)

i1; i2; i3; i4; i5
```




# Fitting model to the full data set

```{r, echo = FALSE}
x <- oshitar::variable_setup(x)

final <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC") + pspline(text_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC"), data = x)
summary(final)
AIC(final, k = 2) # 83051.61

x$predictions <- predict(final, type = "risk")
(performance <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = x))
AIC(performance, k = 2)

# extracting predicted survival probabilities
prob <- pec::predictSurvProb(final, newdata = x, times = c(0.5, 1, 1.5, 2, quantile(x$time_until_answer)))


#==================================================================================
# function to take in a data set, fit the model, output performance metrics, and allow you to specify times to predict survival probabilities 

predict_survprob <- function(dataset, times) {
  # fitting the model 
  data <- oshitar::variable_setup(dataset)
  model <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh + new_user*update + new_user*ampm + new_category*new_user, data = data)
  
  # performance metrics
  data[["predictions"]] <- predict(model, type = "risk")
  p <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = data)
  metrics <- data.frame(HR = exp(p$coefficients), 
                             LR = round(p$stats[3],2), 
                             pval = round(p$stats[5],2), 
                             R2 = round(p$stats[8],2), 
                             Dxy = round(p$stats[9],2), 
                             AIC = stats::AIC(p, k = 2), 
                             Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = data)$concordance)
  
  # calculating predicted survival probabilities
  probs <- pec::predictSurvProb(model, newdata = data, times)
  
  # returns a list containing performance metrics, and data frame with predicted survival probabilities
  output <- list(metrics, probs)
  return(output)
}
```

