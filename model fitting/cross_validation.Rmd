---
title: "Predictive modeling with cross validation (this file is a mess)"
author: "Lisa Oshita"
date: "8/10/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
x <- oshitar::setup()
library(survival); library(stringr); library(rebus); library(dplyr); library(stats); library(rms)
```

```{r, cross validation, echo = FALSE}
# creating cross-validation plan with k = 5
set.seed(444)
splitPlan <- vtreat::kWayCrossValidation(nrow(x), 5, NULL, NULL)

train1 <- x[splitPlan[[1]]$train, ]; test1 <- x[splitPlan[[1]]$app, ]
train2 <- x[splitPlan[[2]]$train, ]; test2 <- x[splitPlan[[2]]$app, ]
train3 <- x[splitPlan[[3]]$train, ]; test3 <- x[splitPlan[[3]]$app, ]
train4 <- x[splitPlan[[4]]$train, ]; test4 <- x[splitPlan[[4]]$app, ]
train5 <- x[splitPlan[[5]]$train, ]; test5 <- x[splitPlan[[5]]$app, ]
```

### Building the model on one of the training data sets

##### Fitting model with all significant variables

* univariate analysis p-value < 0.01
* using stepAIC to perform backwards and forwards stepwise variable selection with AIC criteria 

```{r, echo = FALSE}
# fitted with penalized spline smoothing with AIC criteria on device_length and avg_tag_length
fit <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + log10(text_length) + title_questionmark + title_beginwh + sqrt(newline_ratio) + sqrt(avg_tag_score) + text_contain_punct + text_all_lower + update + greeting + as.factor(n_tags) + gratitude + prior_effort + ampm + n_images + weekday + pspline(device_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC"), data = train1)

#model <- MASS::stepAIC(fit, direction = "both", k = 2)

# results of stepAIC (including contain_answered)
results <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + 
    contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + 
    text_all_lower + update + prior_effort + ampm + weekday + 
    pspline(device_length, df = 0, method = "AIC") + pspline(avg_tag_length, 
    df = 0, method = "AIC"), data = train1)
AIC(results2, k = 2) # 64866.93
```

##### Splines 

* adding in splines one at a time 

```{r}
# spline on device_length
spline <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC"), data = train1)
AIC(spline, k = 2) # 64907.21
summary(spline)

# spline on text_length
spline1 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(text_length, df = 0, method = "AIC"), data = train1)
AIC(spline1, k = 2) # 64914.27

# spline on avg_tag_length
spline2 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(avg_tag_length, df = 0, method = "AIC"), data = train1)
AIC(spline2, k = 2) # 64893.52

# spline on avg_tag_length + device_length
spline3 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC"), data = train1)
AIC(spline3, k = 2) # 64865.95

# spline on newline_ratio
spline4 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(newline_ratio, df = 0, method = "AIC"), data = train1)
AIC(spline4, k = 2) # 64915.6

# log10(text_length), spline = avg_tag_length + device_length
spline5 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + log10(text_length) + sqrt(newline_ratio) + pspline(device_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC"), data = train1)
AIC(spline5, k = 2) # 64865.73

# log10(text_length), sqrt(newline_ratio), spline = avg_tag_length + device_length
spline6 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + log10(text_length) + sqrt(newline_ratio) + pspline(device_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC"), data = train1)
AIC(spline6, k = 2) # 64864.73

# title_beginwh*title_questionmark, log10(text_length), sqrt(newline_ratio), spline = avg_tag_length + device_length
spline7 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + log10(text_length) + sqrt(newline_ratio) + pspline(device_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC") + title_beginwh + title_questionmark*title_beginwh, data = train1)
AIC(spline7, k = 2) # 64858.68 

# title_beginwh*title_questionmark, log10(text_length), sqrt(newline_ratio), spline = avg_tag_length + device_length + newline_ratio
spline8 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + log10(text_length) + sqrt(newline_ratio) + pspline(device_length, df = 0, method = "AIC") + pspline(avg_tag_length, df = 0, method = "AIC") + title_beginwh + pspline(newline_ratio, df = 0, method = "AIC") + title_questionmark*title_beginwh, data = train1)
AIC(spline8, k = 2) # 64841.25
```

##### Restricted cubic splines  

* using rcs (restricted cubic spline) in rms package
* fit knots at quantiles of the predictor 
* recommended in Regression Modeling Strategies to have 5 knots for large data sets 
* estimates less parameters than penalized spline smoothing with AIC criteria 
* **AIC is higher for these splines** 

```{r}
library(rms)
model <- cph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + contain_answered + title_questionmark + text_all_lower + update + prior_effort + ampm + weekday + rcs(device_length, 5) + sqrt(avg_tag_score) + rcs(text_length, 3) + rcs(avg_tag_length, 3) + rcs(newline_ratio, 3), data = train1)
AIC(model, k = 2) # 64977.65
```

##### Interactions

* probably not going to include any interactions - don't do much for the model 

```{r, echo = FALSE}
# adding interaction between title_questionmark + title_beginwh 
reduced <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + title_beginwh + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday, data = train1) # title_beginwh was not included in result from stepAIC, added in this model to compare it to the model with the interaction 

interaction <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + title_beginwh + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + title_questionmark*title_beginwh, data = train1)
summary(interaction)
AIC(interaction, k = 2) # 64963.33 barely drops 
oshitar::compare_nested(interaction, reduced)
```

### Final model(??)

* Regression Modeling Strategies by Frank Harrell pointed out that full models perform the same/if not better than models from stepwise selection
* this model:
    + contains all variables
    + puts splines on all quantitative variables (except for avg_tag_score)
    + device_length might be a better predictor- set a spline with 5 knots, other variables not throught to be as signficant have 3 knots 

```{r}
full <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + contain_answered + title_questionmark + title_beginwh + text_contain_punct + text_all_lower + update + greeting + n_tags + gratitude + prior_effort + ampm + weekday + n_images + sqrt(avg_tag_score) + pspline(device_length, df = 5) + pspline(text_length, 3) + pspline(avg_tag_length, 3) + pspline(newline_ratio, 3), data = train1)
AIC(full, k = 2)
```

### Performance metric on training data set

```{r}
train1$predictions <- predict(object = full , type = "risk")
performance <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = train1, x = TRUE, y = TRUE, se.fit = TRUE, residuals = TRUE)
performance

survConcordance(Surv(time_until_answer, answered) ~ predictions, data = train1) # Concordance = 0.6382697
Hmisc::rcorrcens(Surv(time_until_answer, answered) ~ predictions, data = train1)
```

### Predicting on the test data

```{r, include = FALSE}
# function to perform cross validation
# vars is a string of variables, ex: "new_category + new_user..."
# outputs df with performance metrics (for model on train and test data 
crossval <- function(vars, train, test) {
  formula <- paste("Surv(time_until_answer, answered) ~ ", vars, sep = "")
  model <- survival::coxph(as.formula(formula), data = train)
  
  train[["predictions"]] <- predict(model, type = "risk")
  metric <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = train)
  train_metrics <- data.frame(HR = exp(metric$coefficients), 
                              LR = round(metric$stats[3],2), 
                              pval = round(metric$stats[5],2), 
                              AIC = stats::AIC(metric, k = 2),
                              Dxy = round(metric$stats[9],2), 
                              Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = train)$concordance)
  
  # predicting on test data
  test[["predictions"]] <- predict(model, newdata = test, type = "risk")
  
  # computing performance metrics 
  metric1 <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = test)
  test_metrics <- data.frame(HR = exp(metric1$coefficients), 
                             LR = round(metric1$stats[3],2), 
                             pval = round(metric1$stats[5],2), 
                             AIC = stats::AIC(metric1, k = 2),
                             Dxy = round(metric1$stats[9],2), 
                             Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = test)$concordance)
  
  # returns data frame with train/test metrics 
  statistics <- rbind(train_metrics, test_metrics)
  rownames(statistics) <- c("Training Data", "Test Data")
  return(statistics) 
  
}

# function to get average performance metric for each iteration of cv 
# takes list of performance metrics (output from purrr::map(..crossval))
get_avgmetrics <- function(list) {
  avg <- rbind(train_avg = colMeans(purrr::map_df(1:length(list), ~rbind(list[[.]][1,]))), test_avg = colMeans(purrr::map_df(1:length(list), ~rbind(list[[.]][2,]))))
  return(avg)
}

```


```{r, echo = FALSE}
trains <- list(train1, train2, train3, train4, train5)
tests <- list(test1, test2, test3, test4, test5)

# model with penalized AIC splines on device, text, tag length 
allvars <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = 'AIC') + pspline(text_length, df = 0, method = 'AIC') + pspline(avg_tag_length, df = 0, method = 'AIC')"
devtexttag <- purrr::map2(trains, tests, ~crossval(allvars, .x, .y))
devtexttag
# 5th iteration: pvalue for loglikelihood ratio test = 0.51 on test data 
```

```{r}
# penalized AIC spline on device length only 
devvars <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = 'AIC')"
dev <- purrr::map2(trains, tests, ~crossval(devvars, .x, .y))
dev
```

```{r}
# penalized AIC spline on text length only
varstext <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(text_length, df = 0, method = 'AIC')"

text <- purrr::map2(trains, tests, ~crossval(varstext, .x, .y))
```

```{r}
# penalized AIc spline on tag length only 
varstag <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(avg_tag_length, df = 0, method = 'AIC')"

tag <- purrr::map2(trains, tests, ~crossval(varstag, .x, .y))
```

```{r}
# penalized AIc spline on newline ratio only 
varsnew <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(newline_ratio, df = 0, method = 'AIC')"

newline <- purrr::map2(trains, tests, ~crossval(varsnew, .x, .y))
```


```{r}
# penalized splines on dev and text length (both had most signficant p values out of all splines in univariate analysis)
devtextvars <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + pspline(device_length, df = 0, method = 'AIC') + pspline(text_length, df = 0, method = 'AIC')"

devtext <- purrr::map2(trains, tests, ~crossval(devtextvars, .x, .y))

```

```{r}
# with log10(text_length) and spline on dev length (going off of univariate p-values) 
logtextvars <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + log10(text_length) + pspline(device_length, df = 0, method = 'AIC')"

logtext <- purrr::map2(trains, tests, ~crossval(logtextvars, .x, .y))
```

```{r}
# no splines
vars <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday"
nospline <- purrr::map2(trains, tests, ~crossval(vars, .x, .y))
```

```{r}
# log10(text_length) + sqrt(newline_ratio) + splines: device_length, avg_tag_length + interaction between titlebeginwh*title_questionmark
vars1 <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + log10(text_length) + sqrt(newline_ratio) + pspline(device_length, df = 0, method = 'AIC') + pspline(avg_tag_length, df = 0, method = 'AIC') + title_beginwh + title_questionmark*title_beginwh"

lots <- purrr::map2(trains, tests, ~crossval(vars1, .x, .y))
```

```{r}
# log10(text_length) + sqrt(newline_ratio) + splines: device_length, avg_tag_length, newline_ratio + interaction between titlebeginwh*title_questionmark 
vars2 <- "new_category + as.factor(new_user) + contain_unanswered + contain_answered + title_questionmark + sqrt(avg_tag_score) + text_all_lower + update + prior_effort + ampm + weekday + log10(text_length) + sqrt(newline_ratio) + pspline(device_length, df = 0, method = 'AIC') + pspline(avg_tag_length, df = 0, method = 'AIC') + title_beginwh + pspline(newline_ratio, df = 0, method = 'AIC') + title_questionmark*title_beginwh"

lots2 <- purrr::map2(trains, tests, ~crossval(vars2, .x, .y))
```

```{r}
# splines on device_length and avg_tag_length (FINAL MODEL???)
varsdevtag <- "new_category + as.factor(new_user) + 
    contain_unanswered + title_questionmark + sqrt(avg_tag_score) + 
    text_all_lower + update + prior_effort + ampm + weekday + 
    pspline(device_length, df = 0, method = 'AIC') + pspline(avg_tag_length, 
    df = 0, method = 'AIC')"
devtag <- purrr::map2(trains, tests, ~crossval(varsdevtag, .x, .y))
```

##### full model (all variables) with splines on all continuous variables except for avg_tag_score

```{r}
full <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + contain_answered + title_questionmark + title_beginwh + text_contain_punct + text_all_lower + update + greeting + n_tags + gratitude + prior_effort + ampm + weekday + n_images + sqrt(avg_tag_score) + pspline(device_length, df = 5) + pspline(text_length, 3) + pspline(avg_tag_length, 3) + pspline(newline_ratio, 3), data = train1)

fullvars <- "new_category + new_user + contain_unanswered + contain_answered + title_questionmark + title_beginwh + text_contain_punct + text_all_lower + update + greeting + n_tags + gratitude + prior_effort + ampm + weekday + n_images + sqrt(avg_tag_score) + pspline(device_length, df = 5) + pspline(text_length, 3) + pspline(avg_tag_length, 3) + pspline(newline_ratio, 3)"
full <- purrr::map2(trains, tests, ~crossval(fullvars, .x, .y))
full

ugh <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + contain_answered + title_questionmark + title_beginwh + text_contain_punct + text_all_lower + update + greeting + n_tags + gratitude + prior_effort + ampm + weekday + n_images + sqrt(avg_tag_score) + pspline(device_length, df = 0, method = 'AIC') + pspline(text_length, df = 0, method = 'AIC') + pspline(avg_tag_length, df = 0, method = 'AIC') + pspline(newline_ratio, df = 0, method = 'AIC'), data = train1)

summary(ugh) 
AIC(ugh, k = 2)
```


##### viewing all metrics 

```{r}
# model I came to while trying to correct PH assumption violation 
# stratified on ampm, orthogonal polynomial on text_length (new_category still violates PH)
fullvars <- "new_category + new_user + contain_unanswered + contain_answered + title_questionmark + title_beginwh + text_contain_punct + text_all_lower + update + greeting + n_tags + gratitude + prior_effort + strata(ampm) + weekday + n_images + sqrt(avg_tag_score) + pspline(device_length, df = 5) + poly(text_length, 2) + pspline(avg_tag_length, 3) + pspline(newline_ratio, 3)"
fullcv <- purrr::map2(trains, tests, ~crossval(fullvars, .x, .y))

# turn avg_list into a data frame with rownames???
list <- list(dev, text, tag, newline, devtext, logtext, nospline, lots, lots2, devtag, full)
avg_list <- purrr::map(list, ~get_avgmetrics(.))
```

```{r}
# function to get the average difference between performance metrics for training and test data 
get_avgdiff <- function(list) {
  list_diff <- purrr::map(1:length(list), ~diff(as.matrix(list[[.]], lag = 1)))
  df <- plyr::ldply(list_diff, data.frame) %>%
    select(HR, Dxy, Concordance) %>%
    colMeans()
  return(df)
}

# find a way to put rownames on df_diff in a reproducible way 
l_diff <- purrr::map(list, ~get_avgdiff(.))
df_diff <- plyr::ldply(purrr::map(1:length(l_diff), ~data.frame(as.list(l_diff[[.]]))))
df_diff
#least amount of average change found in model with only the spline on newline_ratio 
```


```{r}
# plotting predictions against observed values (calibration plot?)
# final_train1 <- coxph(Surv(time_until_answer, answered) ~ new_category + as.factor(new_user) + 
#     contain_unanswered + title_questionmark + sqrt(avg_tag_score) + 
#     text_all_lower + update + prior_effort + ampm + weekday + 
#     pspline(device_length, df = 0, method = 'AIC') + pspline(avg_tag_length, 
#     df = 0, method = 'AIC'), data = train1)
# train1$predictions <- predict(final_train1, type = "risk")
# 
# ggplot(train1, aes(x = time_until_answer, y = predictions)) + 
#   geom_point() + 
#   ggtitle("Calibration plot")
# # identify the point at around t = 0 with an incorrect prediction
# 
# test1$predictions <- predict(final_train1, newdata = test1, type = "risk")
# ggplot(train1, aes(x = time_until_answer, y = predictions)) + 
#   geom_point()
```


```{r, echo = FALSE}
# function to take in a data set, fit the model, output performance metrics, and allow you to specify times to predict survival probabilities 

predict_survprob <- function(dataset, times) {
  # fitting the model 
  data <- oshitar::variable_setup(dataset)
  model <- coxph(Surv(time_until_answer, answered) ~ new_category + new_user + contain_unanswered + title_questionmark + num_freq_tags + contain_answered + text_all_lower + update + ampm + weekday + device_length + title_beginwh + title_questionmark*title_beginwh + new_user*update + new_user*ampm + new_category*new_user, data = data)
  
  # performance metrics
  data[["predictions"]] <- predict(model, type = "risk")
  p <- rms::cph(Surv(time_until_answer, answered) ~ predictions, data = data)
  metrics <- data.frame(HR = exp(p$coefficients), 
                             LR = round(p$stats[3],2), 
                             pval = round(p$stats[5],2), 
                             R2 = round(p$stats[8],2), 
                             Dxy = round(p$stats[9],2), 
                             AIC = stats::AIC(p, k = 2), 
                             Concordance = survConcordance(Surv(time_until_answer, answered) ~ predictions, data = data)$concordance)
  
  # calculating predicted survival probabilities
  probs <- pec::predictSurvProb(model, newdata = data, times)
  
  # returns a list containing performance metrics, and data frame with predicted survival probabilities
  output <- list(metrics, probs)
  return(output)
}
```

